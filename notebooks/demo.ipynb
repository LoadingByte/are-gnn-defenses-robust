{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0965d3f5",
   "metadata": {},
   "source": [
    "# Demo\n",
    "\n",
    "This notebook introduces the code's structure and functionality by demonstrating how to successfully attack various different models with appropriate (adaptive) attack strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c2ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234bb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cora\"\n",
    "A, X, y = gb.data.get_dataset(dataset)\n",
    "N, D = X.shape\n",
    "C = y.max().item() + 1\n",
    "train_nodes, val_nodes, test_nodes = gb.data.get_splits(y)[0]  # [0] = select first split\n",
    "\n",
    "A = A.cuda()\n",
    "X = X.cuda()\n",
    "y = y.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06542f60",
   "metadata": {},
   "source": [
    "## Global Attack on Vanilla GCN\n",
    "\n",
    "This cell allows you to run evasion or poisoning attacks with different attack algorithms. At two points, you select exactly one of the provided code fragments to achieve various attacks. In any case, the found perturbation is evaluated both in the evasion and poisoning scenarios.\n",
    "\n",
    "- \"Aux-Attack\" computes an evasion attack, either with the \"FGA\" or \"PGD\" optimizers.\n",
    "- \"Meta-Attack\" computes a poisoning attack.\n",
    "    - Using the \"Greedy\" optimizer (giving Metattack) works best with \"SGD\".\n",
    "    - Using the \"PGD\" optimizer (giving Meta-PGD) works best with \"Adam\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d5edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean test acc:    0.8465794324874878\n",
      "Adversarial edges: 299\n",
      "Evasion test acc:  0.7328973412513733\n",
      "Poisoned test acc: 0.7449697852134705\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "fit_kwargs = dict(lr=1e-2, weight_decay=5e-4)\n",
    "budget = 300\n",
    "\n",
    "def make_model():\n",
    "    return gb.model.GCN(n_feat=D, n_class=C, hidden_dims=[16], dropout=0.5).cuda()\n",
    "\n",
    "aux_model = make_model()\n",
    "aux_model.fit((A, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "\n",
    "def loss_fn(A_flip):\n",
    "    A_pert = A + A_flip * (1 - 2 * A)\n",
    "\n",
    "    ############### Aux-Attack ###############\n",
    "    model = aux_model\n",
    "    ########### Meta-Attack w/ SGD ###########\n",
    "    # meta_fit_kwargs = fit_kwargs | dict(optimizer=\"sgd\", lr=1, yield_best=False, patience=None, max_epochs=100)\n",
    "    # model = make_model()\n",
    "    # model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **meta_fit_kwargs, differentiable=A_pert.requires_grad)\n",
    "    ########### Meta-Attack w/ Adam ##########\n",
    "    # model = make_model()\n",
    "    # model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs, differentiable=A_pert.requires_grad)\n",
    "    ##########################################\n",
    "\n",
    "    scores = model(A_pert, X)\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()\n",
    "\n",
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]\n",
    "\n",
    "########### FGA for Aux-Attack ###########\n",
    "# pert = gb.attack.greedy_grad_descent(A.shape, True, A.device, [budget], grad_fn, flips_per_iteration=budget, max_iterations=1)[0]\n",
    "########### PGD for Aux-Attack ###########\n",
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn, base_lr=0.1)\n",
    "######### Greedy for Meta-Attack #########\n",
    "# pert = gb.attack.greedy_grad_descent(A.shape, True, A.device, [budget], grad_fn, flips_per_iteration=1)[0]\n",
    "########### PGD for Meta-Attack ##########\n",
    "# pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn, base_lr=0.01, grad_clip=1)\n",
    "##########################################\n",
    "\n",
    "print(\"Clean test acc:   \", gb.metric.accuracy(aux_model(A, X)[test_nodes], y[test_nodes]).item())\n",
    "\n",
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)\n",
    "print(\"Adversarial edges:\", pert.shape[0])\n",
    "print(\"Evasion test acc: \", gb.metric.accuracy(aux_model(A_pert, X)[test_nodes], y[test_nodes]).item())\n",
    "\n",
    "pois_model = make_model()\n",
    "pois_model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "print(\"Poisoned test acc:\", gb.metric.accuracy(pois_model(A_pert, X)[test_nodes], y[test_nodes]).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494001f",
   "metadata": {},
   "source": [
    "## Global Attack on SVD-GCN\n",
    "\n",
    "Comment out the \"w/ weights\" part to observe how much our custom weighting scheme improves the attack. Like before, choose between FGA, PGD, and Meta-PGD attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d2cbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean test acc:    0.7741448283195496\n",
      "Adversarial edges: 300\n",
      "Evasion test acc:  0.6644868850708008\n",
      "Poisoned test acc: 0.6715291738510132\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "rank = 50\n",
    "fit_kwargs = dict(lr=1e-2, weight_decay=5e-4)\n",
    "budget = 300\n",
    "\n",
    "def make_model():\n",
    "    return gb.model.GraphSequential(OrderedDict(\n",
    "        low_rank=gb.model.PreprocessA(lambda A: gb.preprocess.low_rank(A, rank)),\n",
    "        gcn=gb.model.GCN(n_feat=D, n_class=C, hidden_dims=[16], dropout=0.5)\n",
    "    )).cuda()\n",
    "\n",
    "aux_model = make_model()\n",
    "aux_model.fit((A, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "\n",
    "A_low_rank = aux_model.low_rank(A)\n",
    "A_weights = gb.metric.eigenspace_alignment(A, rank)\n",
    "\n",
    "def loss_fn(A_flip):\n",
    "    A_diff = A_flip * (1 - 2 * A)\n",
    "\n",
    "    ############# w/ weights #############\n",
    "    A_diff = A_diff * A_weights\n",
    "    ######################################\n",
    "\n",
    "    A_pert = A_low_rank + A_diff\n",
    "\n",
    "    ############# Aux-Attack #############\n",
    "    model = aux_model.sub(exclude=[\"low_rank\"])\n",
    "    ############# Meta-Attack ############\n",
    "    # model = make_model().sub(exclude=[\"low_rank\"])\n",
    "    # model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs, differentiable=A_pert.requires_grad)\n",
    "    ######################################\n",
    "\n",
    "    scores = model(A_pert, X)\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()\n",
    "\n",
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]\n",
    "\n",
    "########### FGA for Aux-Attack ###########\n",
    "# pert = gb.attack.greedy_grad_descent(A.shape, True, A.device, [budget], grad_fn, flips_per_iteration=budget, max_iterations=1)[0]\n",
    "########### PGD for Aux-Attack ###########\n",
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn, base_lr=0.1)\n",
    "########### PGD for Meta-Attack ##########\n",
    "# pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn, base_lr=0.1, grad_clip=0.1)\n",
    "##########################################\n",
    "\n",
    "print(\"Clean test acc:   \", gb.metric.accuracy(aux_model(A, X)[test_nodes], y[test_nodes]).item())\n",
    "\n",
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)\n",
    "print(\"Adversarial edges:\", pert.shape[0])\n",
    "print(\"Evasion test acc: \", gb.metric.accuracy(aux_model(A_pert, X)[test_nodes], y[test_nodes]).item())\n",
    "\n",
    "pois_model = make_model()\n",
    "pois_model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "print(\"Poisoned test acc:\", gb.metric.accuracy(pois_model(A_pert, X)[test_nodes], y[test_nodes]).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10478a",
   "metadata": {},
   "source": [
    "## Global Attack on GNNGuard\n",
    "\n",
    "Swap out the \"w/ changed div_limit\" part for \"w/ real div_limit\" to observe how much tuning this single hyperparameter during the attack improves its efficacy. Like before, choose between PGD and Meta-PGD attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047a42cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean test acc:    0.8390341997146606\n",
      "Adversarial edges: 299\n",
      "Evasion test acc:  0.7494969367980957\n",
      "Poisoned test acc: 0.7525150775909424\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "rank = 50\n",
    "fit_kwargs = dict(lr=1e-2, weight_decay=5e-4)\n",
    "budget = 300\n",
    "\n",
    "def make_model(div_limit=1e-6):\n",
    "    return gb.model.GNNGuard(n_feat=D, n_class=C, hidden_dims=[16], dropout=0.5, div_limit=div_limit).cuda()\n",
    "\n",
    "aux_model = make_model()\n",
    "aux_model.fit((A, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "\n",
    "def loss_fn(A_flip):\n",
    "    A_diff = A_flip * (1 - 2 * A)\n",
    "    A_pert = A + A_diff\n",
    "\n",
    "    ########## w/ real div_limit #########\n",
    "    # alteration = dict()\n",
    "    ######## w/ changed div_limit ########\n",
    "    alteration = dict(div_limit=1e-2)\n",
    "    ######################################\n",
    "\n",
    "    ############# Aux-Attack #############\n",
    "    with gb.model.changed_fields(aux_model, **alteration):\n",
    "        scores = aux_model(A_pert, X)\n",
    "    ############# Meta-Attack ############\n",
    "    # model = make_model(**alteration)\n",
    "    # model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs, max_epochs=50, differentiable=A_pert.requires_grad)\n",
    "    # scores = model(A_pert, X)\n",
    "    ######################################\n",
    "\n",
    "    return gb.metric.margin(scores[test_nodes, :], y[test_nodes]).tanh().mean()\n",
    "\n",
    "def grad_fn(A_flip):\n",
    "    return torch.autograd.grad(loss_fn(A_flip), A_flip)[0]\n",
    "\n",
    "########### PGD for Aux-Attack ###########\n",
    "pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn, base_lr=0.1)\n",
    "########### PGD for Meta-Attack ##########\n",
    "# pert, _ = gb.attack.proj_grad_descent(A.shape, True, A.device, budget, grad_fn, loss_fn, base_lr=0.1, grad_clip=0.1)\n",
    "##########################################\n",
    "\n",
    "print(\"Clean test acc:   \", gb.metric.accuracy(aux_model(A, X)[test_nodes], y[test_nodes]).item())\n",
    "\n",
    "A_pert = A + gb.pert.edge_diff_matrix(pert, A)\n",
    "print(\"Adversarial edges:\", pert.shape[0])\n",
    "print(\"Evasion test acc: \", gb.metric.accuracy(aux_model(A_pert, X)[test_nodes], y[test_nodes]).item())\n",
    "\n",
    "pois_model = make_model()\n",
    "pois_model.fit((A_pert, X), y, train_nodes, val_nodes, progress=False, **fit_kwargs)\n",
    "print(\"Poisoned test acc:\", gb.metric.accuracy(pois_model(A_pert, X)[test_nodes], y[test_nodes]).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
